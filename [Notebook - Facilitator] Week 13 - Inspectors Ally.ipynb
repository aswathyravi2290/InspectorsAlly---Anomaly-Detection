{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651ed93a",
   "metadata": {
    "id": "651ed93a"
   },
   "source": [
    "## Visual Quality Control Inspections\n",
    "\n",
    "**Improve Automated Inspection with Computer Vision**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3393a07",
   "metadata": {
    "id": "a3393a07"
   },
   "source": [
    "A model that classifies images as 'Good' / 'Anomaly'. Trained without any labels for defective regions, model in the inference mode is able to predict a bounding box for a defective region in the image. This is achieved by processing feature maps of the deep convolutional layers. AI-powered systems can inspect products for defects with a high degree of accuracy, which can help to reduce the number of defective products that are produced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd392f5",
   "metadata": {
    "id": "8fd392f5"
   },
   "source": [
    "### Visual Quality Control Inspections as a AI for Manufacturing Usecase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8feba",
   "metadata": {
    "id": "43f8feba"
   },
   "source": [
    "**Automating visual quality control inspections for life sciences can be considered a use case of AI in manufacturing. In life sciences, AI-powered visual quality control inspections involve using computer vision algorithms to analyze images and videos of products, such as drugs, medical devices, and biologics, to identify defects, contaminants, or other issues that may affect product quality.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2824ac",
   "metadata": {
    "id": "1c2824ac"
   },
   "source": [
    "## AI Project Cycle ![AI_Project_Cycle.png](docs/AI_Project_Cycle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255946bd",
   "metadata": {
    "id": "255946bd"
   },
   "source": [
    "## Context: Understanding the Problem Statement --------Problem Scoping (AI Project Cycle - Step 1)\n",
    "\n",
    "**An Deep Learning based classification solution for Defect Detection Using Convolutional Neural Networks**\n",
    "\n",
    "- In manufacturing life sciences products, visual quality control inspections are an important step in ensuring that products meet the necessary standards for safety and efficacy. AI-based visual inspection systems can help to automate this process by analyzing images and videos of products in real time, identifying defects, and flagging any issues that may arise. This can help to improve the speed and accuracy of visual inspections and ensure that only high-quality products reach the market.\n",
    "\n",
    "- Additionally, AI-based visual inspection systems can also be used to monitor the manufacturing process, identifying any issues that may arise during production and helping to prevent defects from occurring in the first place. Overall, automating visual quality control inspections for life sciences is a good example of AI in manufacturing use case which helps to improve the overall quality and safety of life sciences products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269938b",
   "metadata": {
    "id": "1269938b"
   },
   "source": [
    "### Import the useful Packages & Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f89a7",
   "metadata": {},
   "source": [
    "To know more about the pytorch click [here](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ad0e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp38-cp38-win_amd64.whl (172.4 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479431f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 998.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from networkx->torch==2.0.1->torchvision) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08507e57",
   "metadata": {},
   "source": [
    "To know more about Os module just click [here](https://www.geeksforgeeks.org/os-module-python-examples/)\n",
    "\n",
    "To know more about what is Seaborn click [here](https://seaborn.pydata.org/tutorial.html)\n",
    "\n",
    "To know more about matrices and scoring click [here](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "To know more about warnings click [here](https://docs.python.org/3/library/warnings.html#:~:text=Warning%20messages%20are%20typically%20issued,program%20uses%20an%20obsolete%20module.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc40814",
   "metadata": {
    "id": "2dc40814"
   },
   "outputs": [],
   "source": [
    "# Import the os module to perform operating system-related tasks\n",
    "import os\n",
    "\n",
    "# Import the NumPy library for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Import the PIL library for image manipulation\n",
    "from PIL import Image\n",
    "\n",
    "# Import the PyTorch library for deep learning\n",
    "import torch\n",
    "\n",
    "# Import PyTorch's data loading utilities\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Import PyTorch's image transformation utilities\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import scikit-learn's utilities for splitting data into train/test sets and for k-fold cross-validation\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Import the Matplotlib library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Matplotlib's Rectangle object for drawing bounding boxes\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Import the Seaborn library for visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Import scikit-learn's utilities for evaluating classification performance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Define a constant string variable for the name of the folder containing the \"good\" class images\n",
    "GOOD_CLASS_FOLDER = \"good\"\n",
    "\n",
    "# Define a constant list variable for the dataset splits\n",
    "DATASET_SETS = [\"train\", \"test\"]\n",
    "\n",
    "# Define a constant string variable for the format of the image files\n",
    "IMG_FORMAT = \".png\"\n",
    "\n",
    "# Define a constant tuple variable for the size of the input images\n",
    "INPUT_IMG_SIZE = (224, 224)\n",
    "\n",
    "# Define a constant integer variable for the negative class label\n",
    "NEG_CLASS = 1\n",
    "\n",
    "# Import the warnings module to suppress warnings in the code\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings that may be raised during the code execution\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a491c17",
   "metadata": {
    "id": "1a491c17"
   },
   "source": [
    "## Dataset:  Data Acquisition (AI Project Cycle - Step 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1613dbdb",
   "metadata": {
    "id": "1613dbdb"
   },
   "source": [
    "Dataset used - [MVTEC Anomaly Detection Dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad). This dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0), which means it is not allowed to use it for commercial purposes.\n",
    "\n",
    "This MVTec anomaly detection dataset (MVTec AD) is built with data derived from augmentation techniques, such as histogram equalization, letterbox, random perspective, flip, scaling, and rotation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d52feb",
   "metadata": {
    "id": "77d52feb"
   },
   "source": [
    "DataSet: https://www.mvtec.com/company/research/datasets/mvtec-ad (only download Leather dataset for this use case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614802de",
   "metadata": {
    "id": "614802de"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "The leather dataset is downloaded and extracted in a folder before running the training Python module.\n",
    "\n",
    "The dataset available from the source requires filtering before the training. Assuming the leather dataset is downloaded from the dataset source given above in this document, Follow the below steps to filter the dataset extracted from the source.\n",
    "\n",
    "<code>tar -xf leather.tar.xz</code>\n",
    " \n",
    "<code>mkdir -p data/{train/{good,bad},test/{good,bad}}</code>   \n",
    "    \n",
    "<code>cd leather/train/good/\n",
    " cp $(ls | head -n 210) ../../../data/train/good/\n",
    " cp $(ls | tail -n 65) ../../../data/test/good/ \n",
    "</code>\n",
    " \n",
    "<code>cd leather/test/combined\n",
    " cp $(ls | head -n 17) ../../../data/train/bad/\n",
    " cp $(ls | tail -n 5) ../../../data/test/bad/\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c864791",
   "metadata": {
    "id": "0c864791"
   },
   "source": [
    "![overview_dataset](docs/overview_dataset.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6eece",
   "metadata": {
    "id": "3de6eece"
   },
   "source": [
    "## Data Preprocessing ------ Data Exploration(AI Project Cycle - Step 3)\n",
    "\n",
    "Data exploration is performed to gather information on data and based on the gained insights, various pre-processing functions are implemented. \n",
    "\n",
    "\n",
    "Here, A custom dataset class, called MVTEC_AD_DATASET has been defined that is meant to be used with the MVTEC Anomaly Detection dataset. The dataset contains images and associated labels, which can be used to train and evaluate machine learning models.\n",
    "\n",
    "The class inherits from the PyTorch Dataset class and implements several methods to allow it to be used with PyTorch's data loading and processing tools. \n",
    "The __init__ method sets up the class by defining some parameters, such as the class labels, which are either \"Good\" and \"Anomaly\". \n",
    "\n",
    "To know more about how to create classes click [here](https://docs.python.org/3/tutorial/classes.html) where as for learning how to create functions click [here](https://www.w3schools.com/python/python_functions.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8204eaa6",
   "metadata": {
    "id": "8204eaa6"
   },
   "outputs": [],
   "source": [
    "class MVTEC_AD_DATASET(Dataset):\n",
    "    \"\"\"\n",
    "    Class to load subsets of MVTEC ANOMALY DETECTION DATASET\n",
    "    Dataset Link: https://www.mvtec.com/company/research/datasets/mvtec-ad\n",
    "    \n",
    "    Root is path to the subset, for instance, `mvtec_anomaly_detection/leather`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root):\n",
    "        # Define the class labels based on the NEG_CLASS setting.\n",
    "        self.classes = [\"Good\", \"Anomaly\"] if NEG_CLASS == 1 else [\"Anomaly\", \"Good\"]\n",
    "        # Define the image transformation pipeline.\n",
    "        self.img_transform = transforms.Compose(\n",
    "            [transforms.Resize(INPUT_IMG_SIZE), transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "        # Load the image filenames and labels for the dataset.\n",
    "        (\n",
    "            self.img_filenames,\n",
    "            self.img_labels,\n",
    "            self.img_labels_detailed,\n",
    "        ) = self._get_images_and_labels(root)\n",
    "\n",
    "    def _get_images_and_labels(self, root):\n",
    "        # Initialize lists to store image filenames and labels.\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        labels_detailed = []\n",
    "\n",
    "        # Loop over the dataset sets (e.g., \"train\", \"test\") and classes (\"good\" and \"anomaly\").\n",
    "        for folder in DATASET_SETS:\n",
    "            # Construct the path to the class folder.\n",
    "            folder = os.path.join(root, folder)\n",
    "\n",
    "            # Loop over the class folders in the dataset.\n",
    "            for class_folder in os.listdir(folder):\n",
    "                # Determine the label for the class based on its folder name.\n",
    "                label = (\n",
    "                    1 - NEG_CLASS if class_folder == GOOD_CLASS_FOLDER else NEG_CLASS\n",
    "                )\n",
    "                # Store the detailed label (i.e., the class folder name).\n",
    "                label_detailed = class_folder\n",
    "\n",
    "                # Construct the path to the class image folder.\n",
    "                class_folder = os.path.join(folder, class_folder)\n",
    "                # Get the list of image filenames in the class folder that match the IMG_FORMAT setting.\n",
    "                class_images = os.listdir(class_folder)\n",
    "                class_images = [\n",
    "                    os.path.join(class_folder, image)\n",
    "                    for image in class_images\n",
    "                    if image.find(IMG_FORMAT) > -1\n",
    "                ]\n",
    "\n",
    "                # Add the class image filenames and labels to the respective lists.\n",
    "                image_names.extend(class_images)\n",
    "                labels.extend([label] * len(class_images))\n",
    "                labels_detailed.extend([label_detailed] * len(class_images))\n",
    "\n",
    "        # Print some statistics about the dataset.\n",
    "        print(\n",
    "            \"Dataset {}: N Images = {}, Share of anomalies = {:.3f}\".format(\n",
    "                root, len(labels), np.sum(labels) / len(labels)\n",
    "            )\n",
    "        )\n",
    "        # Return the lists of image filenames and labels.\n",
    "        return image_names, labels, labels_detailed\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset (i.e., the number of images).\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the filename and label for the image at the specified index.\n",
    "        img_fn = self.img_filenames[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        # Open the image file and apply the image transformation pipeline.\n",
    "        img = Image.open(img_fn)\n",
    "        img = self.img_transform(img)\n",
    "        # Convert the label to a PyTorch tensor.\n",
    "        label = torch.as_tensor(label, dtype=torch.long)\n",
    "        # Return the transformed image and label as a tuple.\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73082a61",
   "metadata": {},
   "source": [
    "To know more about the init function click [here](https://www.geeksforgeeks.org/__init__-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427ac3c",
   "metadata": {
    "id": "d427ac3c"
   },
   "source": [
    "### Splitting and Loading dataset into separate training and test set\n",
    "\n",
    "80% of the data has been used for training and 20% is used for testing. The resulting train and test sets are loaded into PyTorch DataLoaders with the specified batch size.\n",
    "\n",
    "The *get_cv_train_test_loaders* function splits the dataset into train and test sets for N-Fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44578a7a",
   "metadata": {
    "id": "44578a7a"
   },
   "outputs": [],
   "source": [
    "# This function takes in the root directory of the MVTEC_AD dataset, batch size for DataLoader, test_size, and random_state as input arguments.\n",
    "def get_train_test_loaders(root, batch_size, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Returns train and test dataloaders.\n",
    "    Splits dataset in stratified manner, considering various defect types.\n",
    "    \"\"\"\n",
    "    # Initialize the dataset object with the given root directory.\n",
    "    dataset = MVTEC_AD_DATASET(root=root)\n",
    "\n",
    "    # Split the indices of dataset into train and test sets in a stratified manner based on the defect types.\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        np.arange(dataset.__len__()),\n",
    "        test_size=test_size,\n",
    "        shuffle=True,\n",
    "        stratify=dataset.img_labels_detailed,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Initialize the SubsetRandomSampler for the training set and test set.\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    # Initialize the DataLoader objects for the training set and test set with the SubsetRandomSampler.\n",
    "    train_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=test_sampler, drop_last=False\n",
    "    )\n",
    "\n",
    "    # Return the DataLoader objects for the training set and test set.\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# This function takes in the root directory of the MVTEC_AD dataset, batch size for DataLoader, and n_folds as input arguments.\n",
    "def get_cv_train_test_loaders(root, batch_size, n_folds=5):\n",
    "    \"\"\"\n",
    "    Returns train and test dataloaders for N-Fold cross-validation.\n",
    "    Splits dataset in stratified manner, considering various defect types.\n",
    "    \"\"\"\n",
    "    # Initialize the dataset object with the given root directory.\n",
    "    dataset = MVTEC_AD_DATASET(root=root)\n",
    "\n",
    "    # Initialize the StratifiedKFold object for the specified number of folds.\n",
    "    kf = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "    # Initialize an empty list for storing the DataLoader objects for each fold.\n",
    "    kf_loader = []\n",
    "\n",
    "    # Split the dataset into train and test sets for each fold using the StratifiedKFold object.\n",
    "    for train_idx, test_idx in kf.split(\n",
    "        np.arange(dataset.__len__()), dataset.img_labels_detailed\n",
    "    ):\n",
    "        # Initialize the SubsetRandomSampler for the training set and test set.\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "        # Initialize the DataLoader objects for the training set and test set with the SubsetRandomSampler.\n",
    "        train_loader = DataLoader(\n",
    "            dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset, batch_size=batch_size, sampler=test_sampler, drop_last=False\n",
    "        )\n",
    "\n",
    "        # Append the DataLoader objects for the current fold to the list.\n",
    "        kf_loader.append((train_loader, test_loader))\n",
    "\n",
    "    # Return the list of DataLoader objects for all folds.\n",
    "    return kf_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549c8db",
   "metadata": {
    "id": "3549c8db"
   },
   "source": [
    "## Building a Model ------ Modeling ( AI Project Cycle - Step 4)\n",
    "\n",
    "Modeling is the fourth step in the AI project cycle, which involves building a machine learning model to solve a particular problem. This step is where we use the pre-processed data to train a model that can predict the desired outcome. \n",
    "\n",
    "Here, a function called \"train\" has been defined that trains a machine learning model. The function takes several arguments and trains the model by looping over the training data in dataloader for epochs number of times. In each epoch, the model makes predictions on the inputs, calculates the loss between the predictions and the actual labels, and optimizes its parameters based on the loss gradient. The running loss and accuracy are calculated and displayed at the end of each epoch.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e4fa70",
   "metadata": {
    "id": "02e4fa70"
   },
   "outputs": [],
   "source": [
    "# This function takes in the dataloader (for loading training data), the model, optimizer, loss criterion, number of epochs, device to train the model on (CPU or GPU), and an optional target accuracy to stop training early.\n",
    "def train(\n",
    "    dataloader, model, optimizer, criterion, epochs, device, target_accuracy=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Script to train a model. Returns trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # These lines move the model to the specified device (CPU or GPU) and puts the model in train mode.\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # This loop iterates over the number of epochs specified and initializes variables to track loss, accuracy, and number of samples processed during training\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}:\", end=\" \")\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        n_samples = 0\n",
    "\n",
    "        # This inner loop iterates over batches of data from the dataloader, moves the inputs and labels to the specified device, performs forward and backward passes through the model, calculates the loss and updates the model weights via the optimizer, and updates the running loss and accuracy statistics.\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds_scores = model(inputs)\n",
    "            preds_class = torch.argmax(preds_scores, dim=-1)\n",
    "            loss = criterion(preds_scores, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds_class == labels)\n",
    "            n_samples += inputs.size(0)\n",
    "\n",
    "        \n",
    "        # This code calculates the average loss and accuracy over the epoch and prints the results. If a target accuracy is specified, the code checks if the current epoch's accuracy exceeds the target and stops training early if it does.\n",
    "        epoch_loss = running_loss / n_samples\n",
    "        epoch_acc = running_corrects.double() / n_samples\n",
    "        print(\"Loss = {:.4f}, Accuracy = {:.4f}\".format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if target_accuracy != None:\n",
    "            if epoch_acc > target_accuracy:\n",
    "                print(\"Early Stopping\")\n",
    "                break\n",
    "\n",
    "    # This function returns the trained model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da09033",
   "metadata": {
    "id": "4da09033"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set input image size\n",
    "INPUT_IMG_SIZE = (224, 224)\n",
    "\n",
    "class CustomVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom multi-class classification model \n",
    "    with VGG16 feature extractor, pretrained on ImageNet\n",
    "    and custom classification head.\n",
    "    Parameters for the first convolutional blocks are freezed.\n",
    "    \n",
    "    Returns class scores when in train mode.\n",
    "    Returns class probs and normalized feature maps when in eval mode.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(CustomVGG, self).__init__()\n",
    "\n",
    "        # Load VGG16 feature extractor, pretrained on ImageNet\n",
    "        self.feature_extractor = models.vgg16(pretrained=True).features[:-1]\n",
    "\n",
    "        # Define custom classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=(INPUT_IMG_SIZE[0] // 2 ** 5, INPUT_IMG_SIZE[1] // 2 ** 5)\n",
    "            ),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=self.feature_extractor[-2].out_channels,\n",
    "                out_features=n_classes,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Freeze parameters for the first convolutional blocks of the feature extractor\n",
    "        self._freeze_params()\n",
    "\n",
    "    def _freeze_params(self):\n",
    "        # Loop through all parameters for the first 23 convolutional blocks\n",
    "        for param in self.feature_extractor[:23].parameters():\n",
    "            # Freeze parameters\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute feature maps using VGG16 feature extractor\n",
    "        feature_maps = self.feature_extractor(x)\n",
    "\n",
    "        # Compute class scores using custom classification head\n",
    "        scores = self.classification_head(feature_maps)\n",
    "\n",
    "        # If in training mode, return class scores\n",
    "        if self.training:\n",
    "            return scores\n",
    "\n",
    "        # If in evaluation mode, return class probabilities and normalized feature maps\n",
    "        else:\n",
    "            # Compute class probabilities from class scores using softmax activation function\n",
    "            probs = nn.functional.softmax(scores, dim=-1)\n",
    "\n",
    "            # Compute normalized feature maps from classification head weights and feature maps\n",
    "            weights = self.classification_head[3].weight\n",
    "            weights = (\n",
    "                weights.unsqueeze(-1)\n",
    "                .unsqueeze(-1)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(\n",
    "                    (\n",
    "                        x.size(0),\n",
    "                        1,\n",
    "                        1,\n",
    "                        INPUT_IMG_SIZE[0] // 2 ** 4,\n",
    "                        INPUT_IMG_SIZE[0] // 2 ** 4,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            feature_maps = feature_maps.unsqueeze(1).repeat((1, probs.size(1), 1, 1, 1))\n",
    "            location = torch.mul(weights, feature_maps).sum(axis=2)\n",
    "            location = F.interpolate(location, size=INPUT_IMG_SIZE, mode=\"bilinear\")\n",
    "\n",
    "            # Normalize feature maps to range [0, 1]\n",
    "            maxs, _ = location.max(dim=-1, keepdim=True)\n",
    "            maxs, _ = maxs.max(dim=-2, keepdim=True)\n",
    "            mins, _ = location.min(dim=-1, keepdim=True)\n",
    "            mins, _ = mins.min(dim=-2, keepdim=True)\n",
    "            norm_location = (location - mins) / (maxs - mins)\n",
    "\n",
    "            # Return class probabilities and normalized feature maps\n",
    "            return probs, norm_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf72e73",
   "metadata": {
    "id": "abf72e73"
   },
   "source": [
    "## Evaluating the Model ------- Evaluation (AI Project Cycle - Step 5)\n",
    "\n",
    "Evaluation of an AI project refers to the process of evaluating the performance of a model on a test set after it has been trained. The purpose of evaluation is to assess the model's ability to generalize to unseen data and to estimate its accuracy in terms of relevant metrics.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Here,the confusion matrix is generated.                                                                                                                                                       It takes as inputs the true labels (*y_true*) and the predicted labels (*y_pred*) of the test data and an optional argument class_names which provides the names of the classes. The function uses confusion_matrix from scikit-learn to compute the confusion matrix between the true and predicted labels. It then plots the confusion matrix using sns.heatmap from the seaborn library. The plot shows the actual labels on the y-axis and the predicted labels on the x-axis. The color of each cell represents the count of samples that belong to the class in the corresponding row and column.                                                                         The x and y axis labels, title, and figure size are set. Finally, the function displays the plot using *plt.show()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a95ba51f",
   "metadata": {
    "id": "a95ba51f"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Script to evaluate a model after training.\n",
    "    Outputs accuracy and balanced accuracy, draws confusion matrix.\n",
    "    \"\"\"\n",
    "    # Move the model to the specified device\n",
    "    model.to(device)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Get the class names from the dataloader's dataset\n",
    "    class_names = dataloader.dataset.classes\n",
    "\n",
    "    # Initialize variables to keep track of correct predictions, true labels, and predicted labels\n",
    "    running_corrects = 0\n",
    "    y_true = np.empty(shape=(0,))\n",
    "    y_pred = np.empty(shape=(0,))\n",
    "\n",
    "    # Loop through the dataloader's batches\n",
    "    for inputs, labels in dataloader:\n",
    "        # Move the inputs and labels to the specified device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass the inputs through the model and get the predicted probabilities and classes\n",
    "        preds_probs = model(inputs)[0]\n",
    "        preds_class = torch.argmax(preds_probs, dim=-1)\n",
    "\n",
    "        # Move the labels and predicted classes to the CPU and convert them to numpy arrays\n",
    "        labels = labels.to(\"cpu\").numpy()\n",
    "        preds_class = preds_class.detach().to(\"cpu\").numpy()\n",
    "\n",
    "        # Concatenate the true labels and predicted labels to the respective arrays\n",
    "        y_true = np.concatenate((y_true, labels))\n",
    "        y_pred = np.concatenate((y_pred, preds_class))\n",
    "\n",
    "    # Calculate the accuracy and balanced accuracy scores using scikit-learn's metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Print the accuracy and balanced accuracy scores\n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    print(\"Balanced Accuracy: {:.4f}\".format(balanced_accuracy))\n",
    "    print()\n",
    "    # Plot the confusion matrix using seaborn's heatmap function\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names=class_names)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names=\"auto\"):\n",
    "    # Calculate the confusion matrix using scikit-learn's metrics\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    # Create a new figure with a specified size\n",
    "    plt.figure(figsize=[5, 5])\n",
    "    # Plot the confusion matrix as a heatmap using seaborn's heatmap function\n",
    "    sns.heatmap(\n",
    "        confusion,\n",
    "        annot=True,\n",
    "        cbar=False,\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "\n",
    "    # Set the labels and title of the plot\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_bbox_from_heatmap(heatmap, thres=0.8):\n",
    "    \"\"\"\n",
    "    Returns bounding box around the defected area:\n",
    "    Upper left and lower right corner.\n",
    "\n",
    "    Threshold affects size of the bounding box.\n",
    "    The higher the threshold, the wider the bounding box.\n",
    "    \"\"\"\n",
    "    # Create a binary map by thresholding the heatmap\n",
    "    binary_map = heatmap > thres\n",
    "\n",
    "    # Compute the x-coordinate of the left and right edge of the bounding box\n",
    "    x_dim = np.max(binary_map, axis=0) * np.arange(0, binary_map.shape[1])\n",
    "    x_0 = int(x_dim[x_dim > 0].min())\n",
    "    x_1 = int(x_dim.max())\n",
    "\n",
    "    # Compute the y-coordinate of the top and bottom edge of the bounding box\n",
    "    y_dim = np.max(binary_map, axis=1) * np.arange(0, binary_map.shape[0])\n",
    "    y_0 = int(y_dim[y_dim > 0].min())\n",
    "    y_1 = int(y_dim.max())\n",
    "\n",
    "    # Return the four corners of the bounding box\n",
    "    return x_0, y_0, x_1, y_1\n",
    "\n",
    "\n",
    "# The function shows the image, its true label, predicted label and predicted probability. \n",
    "# If the model predicts an anomaly, the function draws a bounding box (bbox) around the defected region and a heatmap.\n",
    "# The plot displays the images in a grid, with each image and its label/prediction information in one subplot. \n",
    "def predict_localize(\n",
    "    model, dataloader, device, thres=0.8, n_samples=9, show_heatmap=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs predictions for the samples in the dataloader.\n",
    "    Shows image, its true label, predicted label and probability.\n",
    "    If an anomaly is predicted, draws bbox around defected region and heatmap.\n",
    "    \"\"\"\n",
    "\n",
    "    # Move model to device and set to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Get class names from dataloader\n",
    "    class_names = dataloader.dataset.classes\n",
    "    \n",
    "    # Convert PyTorch tensor to PIL Image for displaying images\n",
    "    transform_to_PIL = transforms.ToPILImage()\n",
    "\n",
    "    # Calculate number of rows and columns for subplot visualization\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_samples / n_cols))\n",
    "    \n",
    "    # Set figure size\n",
    "    plt.figure(figsize=[n_cols * 5, n_rows * 5])\n",
    "\n",
    "    # Initialize sample counter\n",
    "    counter = 0\n",
    "    \n",
    "    # Iterate over batches in dataloader\n",
    "    for inputs, labels in dataloader:\n",
    "        \n",
    "        # Move batch to device\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Generate predictions and feature maps from model\n",
    "        out = model(inputs)\n",
    "        probs, class_preds = torch.max(out[0], dim=-1)\n",
    "        feature_maps = out[1].to(\"cpu\")\n",
    "\n",
    "        # Iterate over images in batch\n",
    "        for img_i in range(inputs.size(0)):\n",
    "            \n",
    "            # Get image, predicted label, probability, and true label\n",
    "            img = transform_to_PIL(inputs[img_i])\n",
    "            class_pred = class_preds[img_i]\n",
    "            prob = probs[img_i]\n",
    "            label = labels[img_i]\n",
    "            \n",
    "            # Get heatmap for negative class (anomaly) if predicted\n",
    "            heatmap = feature_maps[img_i][NEG_CLASS].detach().numpy()\n",
    "\n",
    "            # Increment subplot counter\n",
    "            counter += 1\n",
    "            \n",
    "            # Create subplot for image\n",
    "            plt.subplot(n_rows, n_cols, counter)\n",
    "            \n",
    "            # Show image and set axis off\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            # Set title with predicted label, probability, and true label\n",
    "            plt.title(\n",
    "                \"Predicted: {}, Prob: {:.3f}, True Label: {}\".format(\n",
    "                    class_names[class_pred], prob, class_names[label]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # If anomaly is predicted (negative class)\n",
    "            if class_pred == NEG_CLASS:\n",
    "                \n",
    "                # Get bounding box from heatmap and draw rectangle around anomaly\n",
    "                x_0, y_0, x_1, y_1 = get_bbox_from_heatmap(heatmap, thres)\n",
    "                rectangle = Rectangle(\n",
    "                    (x_0, y_0),\n",
    "                    x_1 - x_0,\n",
    "                    y_1 - y_0,\n",
    "                    edgecolor=\"red\",\n",
    "                    facecolor=\"none\",\n",
    "                    lw=3,\n",
    "                )\n",
    "                plt.gca().add_patch(rectangle)\n",
    "                \n",
    "                # If show_heatmap is True, show heatmap\n",
    "                if show_heatmap:\n",
    "                    plt.imshow(heatmap, cmap=\"Reds\", alpha=0.3)\n",
    "\n",
    "            # If counter equals number of samples, show plot and return\n",
    "            if counter == n_samples:\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5bfb9",
   "metadata": {
    "id": "bef5bfb9"
   },
   "source": [
    "## Model Deployment Over the Test Dataset ------- Deployment (AI Project Cycle - Step 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe2b04",
   "metadata": {
    "id": "68fe2b04"
   },
   "source": [
    "### Parameters to run the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbf3076",
   "metadata": {
    "id": "fbbf3076"
   },
   "outputs": [],
   "source": [
    "# Setting up the data folder path to \"data/leather\".\n",
    "data_folder = \"data/\"\n",
    "subset_name = \"leather\"\n",
    "data_folder = os.path.join(data_folder, subset_name)\n",
    "\n",
    "# Setting up batch size, target accuracy, learning rate, number of epochs, and class weights.\n",
    "batch_size = 10\n",
    "target_train_accuracy = 0.98\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "class_weight = [1, 3] if NEG_CLASS == 1 else [3, 1]\n",
    "\n",
    "# Determining the device to use for training, either cuda or cpu.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Setting up the threshold value to use for the heatmap and the number of cross-validation folds.\n",
    "heatmap_thres = 0.7\n",
    "n_cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb60b6e",
   "metadata": {
    "id": "dfb60b6e"
   },
   "source": [
    "### Loading the Data\n",
    "\n",
    " Two data loaders for training and testing data are created. \n",
    "\n",
    "*root*, *batch_size*, *test_size* and *random_state* are the four parameters used here.\n",
    " The returned data loaders will be used to feed the data to the model for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d17cd775",
   "metadata": {
    "id": "d17cd775"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/leather\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fb802ff93af1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_loader, test_loader = get_train_test_loaders(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-7-df3f79431cdc>\u001b[0m in \u001b[0;36mget_train_test_loaders\u001b[1;34m(root, batch_size, test_size, random_state)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Initialize the dataset object with the given root directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMVTEC_AD_DATASET\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Split the indices of dataset into train and test sets in a stratified manner based on the defect types.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6c8031d97ca3>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_labels_detailed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         ) = self._get_images_and_labels(root)\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_images_and_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6c8031d97ca3>\u001b[0m in \u001b[0;36m_get_images_and_labels\u001b[1;34m(self, root)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m# Loop over the class folders in the dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_folder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[1;31m# Determine the label for the class based on its folder name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 label = (\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data/leather\\\\train'"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_train_test_loaders(\n",
    "    root=data_folder, batch_size=batch_size, test_size=0.2, random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e75c8",
   "metadata": {
    "id": "c85e75c8"
   },
   "source": [
    "### Model Training\n",
    "Model training is the process of using a set of training data to learn the parameters of a machine learning model. The goal of model training is to find a set of parameters that minimize the difference between the model's predictions and the true target values in the training data.\n",
    "\n",
    "Here, we initialized and set up components for training the model using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa209342",
   "metadata": {
    "id": "fa209342"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\Hp/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 528M/528M [13:02<00:00, 707kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the CustomVGG model and assign it to the variable 'model'.\n",
    "model = CustomVGG()\n",
    "\n",
    "# Convert the class_weight list to a tensor of type FloatTensor and move it to the device (GPU/CPU) specified by 'device'.\n",
    "class_weight = torch.tensor(class_weight).type(torch.FloatTensor).to(device)\n",
    "\n",
    "# Define the Cross Entropy Loss function with the computed class weights and assign it to the variable 'criterion'.\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "\n",
    "# Define the Adam optimizer with the specified learning rate 'lr' and the model's parameters, and assign it to the variable 'optimizer'.\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd16c16",
   "metadata": {
    "id": "bbd16c16"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2f19dd85b523>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Initialize the training process using the train() function with the train_loader, model, optimizer, criterion, epochs, device, and target_train_accuracy parameters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model = train(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the training process using the train() function with the train_loader, model, optimizer, criterion, epochs, device, and target_train_accuracy parameters.\n",
    "model = train(\n",
    "    train_loader, model, optimizer, criterion, epochs, device, target_train_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27284fe7",
   "metadata": {
    "id": "27284fe7"
   },
   "outputs": [],
   "source": [
    "# Save the trained model to the specified path.\n",
    "model_path = f\"weights/{subset_name}_model.h5\"\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941a8b9",
   "metadata": {
    "id": "e941a8b9"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cfe01",
   "metadata": {
    "id": "a77cfe01"
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance of the trained model using the evaluate() function with the test_loader and device parameters.\n",
    "evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb9637",
   "metadata": {
    "id": "26cb9637"
   },
   "source": [
    "### Cross Validation\n",
    "Cross validation is a technique used in machine learning to evaluate the performance of a model by dividing the dataset into subsets, training the model on one subset and testing it on another subset.\n",
    "\n",
    "Pytorch library has been used here to perform cross validation for training and evaluating the model. \n",
    "\n",
    "Overall, we have trained a custom VGG model and evaluated its performance using a cross-validation procedure, where the performance is estimated by averaging over multiple trials with different training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ead13",
   "metadata": {
    "id": "fc5ead13",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the cross-validation folds using the get_cv_train_test_loaders() function with the root, batch_size, and n_folds parameters.\n",
    "cv_folds = get_cv_train_test_loaders(\n",
    "    root=data_folder,\n",
    "    batch_size=batch_size,\n",
    "    n_folds=n_cv_folds,\n",
    ")\n",
    "\n",
    "# Convert the class weights to a tensor and move it to the device.\n",
    "class_weight = torch.tensor(class_weight).type(torch.FloatTensor).to(device)\n",
    "\n",
    "# Define the loss function with the class weights as a CrossEntropyLoss criterion.\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "\n",
    "# Loop through each cross-validation fold and train, evaluate, and print the performance of the model.\n",
    "for i, (train_loader, test_loader) in enumerate(cv_folds):\n",
    "    print(f\"Fold {i+1}/{n_cv_folds}\")\n",
    "    model = CustomVGG()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model = train(train_loader, model, optimizer, criterion, epochs, device)\n",
    "    evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0708bcd",
   "metadata": {
    "id": "e0708bcd"
   },
   "source": [
    "### Visualization\n",
    "\n",
    "Visualization is an easier way to understand the results obtained. \n",
    "\n",
    "Here, you can see that the predicted as well as the true labels for each of the images along with the prediction of the likelihood of a positive outcome known as Probability(*Prob*) have been displayed above with the images. \n",
    "\n",
    "After the model gets trained, The images get classified as '*Good*' or '*Anomaly*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f97d7",
   "metadata": {
    "id": "b60f97d7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make predictions and localize the anomalies for the test dataset using the predict_localize() function with the model, test_loader, device, thres, n_samples, and show_heatmap parameters.\n",
    "predict_localize(\n",
    "    model, test_loader, device, thres=heatmap_thres, n_samples=15, show_heatmap=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ccb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
